{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Agenda__\n",
    "\n",
    "- Difference between population and sample\n",
    "- How can we get a good sample?\n",
    "- Point estimators from sample\n",
    "- Sampling distribution, especially sampling distribution of the mean\n",
    "- Central Limit Theorem - statement and use of it.\n",
    "- Creating confidence intervals around sample mean using CLT\n",
    "- Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Sampling Distributions\n",
    "\n",
    "## Population vs Sample\n",
    "\n",
    "__population__ A population is the set of all elements of interest in a study. (Finite population and infinite population)\n",
    "\n",
    "__sample__ A sample is a subset of the population.\n",
    "\n",
    "### Scenario\n",
    "\n",
    "The mayor's office has hired HBS students to determine a way to fix traffic congestion. A good starting point is to determine out what proportion of the population of DC owns a car.\n",
    "\n",
    "In order for us to make any determinations about a population, we must first get information about it.\n",
    "\n",
    "Because it's impractical to ever usually get data about *everyone* in a population, we must take a sample.\n",
    "\n",
    "Our sample should be:\n",
    "\n",
    "* Randomly selected- every item should have an *equal* chance of being selected\n",
    "* Representative of our population\n",
    "\n",
    "<img src=\"img/sample_pop.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random sampling is not easy to do, let's look at an example:**\n",
    "\n",
    "Imagine you are trying to determine what proportion of DC metro area people own a car\n",
    "\n",
    "* Stand outside of Harvard Square at 12 pm and ask random people until *n* responses\n",
    "\n",
    "* Go to a randomly assigned street corner and at a random time and ask *n* people if they own a car\n",
    "\n",
    "\n",
    "__Objective of Sampling__\n",
    "\n",
    "When we gather a sample, we are trying to minimize the bias of our sample while also minimizing our cost.\n",
    "\n",
    "\n",
    "## Point Estimates\n",
    "\n",
    "!! Very important observation!!: We can consider random sampling as an 'random experiment' and then when we calculate mean, variance, standard deviation, median etc. these are functions on the outcomes of this experiment. We have a name for such functions can you remember it?\n",
    "\n",
    "<img src=\"img/sample_stats.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's your turn\n",
    "\n",
    "[Download data](https://www.kaggle.com/ishaanv/ISLR-Auto)\n",
    "\n",
    "[UCI-repo](https://archive.ics.uci.edu/ml/datasets/auto+mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take two random samples of 30 cars from auto dataset and find both sampling mean and standard deviation for mpg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We \"pickled\" two samples before and use these to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.pkl', 'rb') as pkl_obj:\n",
    "    sample = pickle.load(pkl_obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the the second sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively\n",
    "sample2 = pd.read_pickle('sample2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the original data. In this case, we will consider this data as \"population\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('data/auto-mpg.csv')\n",
    "mu = auto.mpg.mean()\n",
    "sigma = auto.mpg.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here print population parameters $\\mu$ and $\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the sample mean and the population mean is known as the **Sampling Error**.  \n",
    "\n",
    ">When using the sample mean to estimate the population mean, some possible error will be involved since random sample means are also random.\n",
    "\n",
    "### It's your turn again\n",
    "\n",
    "Repeat the sampling process you did above 1000 times and plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(auto.mpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.mpg.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_means = []\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    mean = auto.sample(n=100).mpg.mean()\n",
    "    sample_means.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_means2 = [auto.sample(n=30).mpg.mean() for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(sample_means, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7.805/np.sqrt(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.mpg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 9-22 supplement.py\n",
    "# taking repeating samples from auto dataset\n",
    "thousand_rand_samp = [auto.sample(n=2).mpg.mean() for i in range(1000)]\n",
    "\n",
    "bars = plt.hist(thousand_rand_samp)\n",
    "\n",
    "plt.vlines(x=mu, ymin=0,\n",
    "           ymax=bars[0].max() + 1,\n",
    "           color='r', label='pop mean')\n",
    "plt.xticks(range(17, 29))\n",
    "plt.xlabel('sample_means')\n",
    "plt.ylabel('frequencies of sample means')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thousand_rand_samp = [auto.sample(n=30).mpg.mean() for i in range(1000)]\n",
    "\n",
    "bars = plt.hist(thousand_rand_samp)\n",
    "\n",
    "plt.vlines(x=mu, ymin=0,\n",
    "           ymax=bars[0].max() + 1,\n",
    "           color='r', label='pop mean')\n",
    "plt.xticks(range(17, 29))\n",
    "plt.xlabel('sample_means')\n",
    "plt.ylabel('frequencies of sample means')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = auto.mpg.std()\n",
    "\n",
    "\n",
    "standard_error = sigma / (np.sqrt(30))\n",
    "\n",
    "standard_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence interval\n",
    "confidence_interval_lower = sample.mpg.mean() - 2*standard_error\n",
    "\n",
    "confidence_interval_upper = sample.mpg.mean() + 2*standard_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_lower_2 = sample2.mpg.mean() - 2*standard_error\n",
    "\n",
    "confidence_interval_upper_2 = sample2.mpg.mean() + 2*standard_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample3 = auto.sample(n=30)\n",
    "\n",
    "confidence_interval_lower_3 = sample3.mpg.mean() - 2*standard_error\n",
    "\n",
    "confidence_interval_upper_3 = sample3.mpg.mean() + 2*standard_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_lower_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval_upper_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.mpg.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Limit Theorem\n",
    "\n",
    "The Central Limit Theorem states: \n",
    ">When you add **a large number** of independent random variables, irrespective of the original distribution of these variables, **their sampling mean distribution tends towards a normal distribution** with mean equals to the mean of the original population and the standard deviation equals to $\\frac{\\sigma}{\\sqrt{n}}$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The standard error of the mean is the standard deviation of the sampling distribution.\n",
    "The issue is that a sample is not an exact replica of the population. We need to account for the fact that in order to make our estimate of the $\\mu$ value possible. Let's break it down:\n",
    "\n",
    "## Standard Error\n",
    "\n",
    "$$\\sigma _{\\bar{X}} = \\frac{\\sigma }{\\sqrt{n}}$$\n",
    "\n",
    "* $ \\sigma _{x}$ = standard error of $\\bar{x} $\n",
    "* $ \\sigma $ = standard deviation of population\n",
    "\n",
    "\n",
    "**What if we do not know the population sigma?**<br>\n",
    "If we do not know the population standard deviation, we can approximate for it by used the sample standard deviation.\n",
    "\n",
    "$\\sigma _{x} ≈ \\frac{s}{\\sqrt{n}}$\n",
    "\n",
    "* s = sample standard deviation\n",
    "\n",
    "But in this case, distribution shape is not 'normal' anymore. In this case the shape will be call 'T-distribution'. We will study this later in more details.\n",
    "\n",
    "\n",
    "**Sample size impact on standard error of mean**<br>\n",
    "\n",
    "Q: How should sample size influence standard error of the mean?\n",
    "\n",
    "\n",
    "![error](./img/diminishing_error.png)\n",
    "Important implication: The Standard Error of the mean remains the same as long as the population standard deviation is known and sample size remains the same.\n",
    "\n",
    "\n",
    "__Note-1__ In the case of finite sampling, we need to adjust the formula for standard error:\n",
    "\n",
    "<img src=\"img/standard_deviation_of_x_bar.png\" width=\"650\">\n",
    "\n",
    "\n",
    "__Note-2__ Note that in CLT the shape of initial distribution is not important! With enough sample size we can always achieve a distribution very close to normal one.\n",
    "\n",
    "<img src=\"img/clt_with_different.png\" width=\"650\">\n",
    "\n",
    "\n",
    "## Interval Estimation - Confidence Intervals\n",
    "\n",
    "Q: Let's assume that we have a sample of size=49 and we know the standard deviation of the population is $\\sigma = 5$. If we know that sampling mean is $\\bar{x} = 20$. What might be a good estimate for the population mean if we also know that the population mean is bigger than 20?\n",
    "\n",
    "Hint: What do we mean by 'a good estimate'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Z-scores](https://www.mathsisfun.com/data/standard-normal-distribution-table.html)\n",
    "\n",
    "<img src=\"img/interval_estimation.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective is to create a 99% confidence interval around the sample mean of mpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bar = sample.mpg.mean()\n",
    "x_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_mpg = auto.mpg.std(ddof=1)\n",
    "sigma_mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sample.shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step size\n",
    "sigma_sampling_mean = sigma / np.sqrt(n)\n",
    "sigma_sampling_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence level %99\n",
    "z_alpha_2 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_alpha_2 = -stats.norm.ppf(0.1)\n",
    "z_alpha_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_bar - z_alpha_2 * sigma_sampling_mean, x_bar + z_alpha_2 * sigma_sampling_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.mpg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# suppose population mu is 21\n",
    "mu = 21\n",
    "# sample mean gives us a point estimator\n",
    "point_estimator = 20\n",
    "\n",
    "# we know population variance is 49\n",
    "std_error = 5/(np.sqrt(49))\n",
    "\n",
    "\n",
    "# how much confidence do we require\n",
    "confidence = 0.95\n",
    "\n",
    "# alpha\n",
    "alpha = 1 - confidence\n",
    "\n",
    "# due to symmetry we divided alpha by 2\n",
    "# note that to find z_alpha_over_2 we used\n",
    "# standard normal distribution\n",
    "\n",
    "z_alpha_over_2 = np.abs(stats.norm.ppf(alpha/2))\n",
    "\n",
    "print(z_alpha_over_2)\n",
    "\n",
    "\n",
    "# upper bound gives us a value so that\n",
    "# 2*(the area between point_estimator - upper_bound) = confidence\n",
    "\n",
    "upper_bound = point_estimator + z_alpha_over_2 * std_error\n",
    "\n",
    "# now let's plot these\n",
    "\n",
    "# a normal distribution with mean=mu and std=sigma\n",
    "x = np.linspace(mu - 4*std_error, mu + 4*std_error, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, mu, std_error))\n",
    "\n",
    "# a vertical line to mark point estimator\n",
    "plt.vlines(point_estimator, ymin=0,\n",
    "           ymax=stats.norm.pdf(point_estimator, mu, std_error))\n",
    "\n",
    "# a vertical line for population mu\n",
    "plt.vlines(mu, ymin=0,\n",
    "           ymax=stats.norm.pdf(mu, mu, std_error),\n",
    "           color='g')\n",
    "\n",
    "# a vertical line for upper bound\n",
    "plt.vlines(upper_bound, ymin=0,\n",
    "           ymax=stats.norm.pdf(upper_bound,\n",
    "                               mu, std_error))\n",
    "\n",
    "\n",
    "# fill the area between upper_bound and point_estimator\n",
    "plt.fill_between(x=np.linspace(point_estimator, upper_bound, 100),\n",
    "                 y1=stats.norm.pdf(np.linspace(point_estimator,\n",
    "                                               upper_bound, 100), mu, std_error),\n",
    "                 facecolor='blue',\n",
    "                 alpha=0.35,\n",
    "                 label='btwn point estimator and\\n upper bound')\n",
    "\n",
    "# fill the area between point estimator and the left of it\n",
    "plt.fill_between(x=np.linspace(mu - 4*std_error, point_estimator, 100),\n",
    "                 y1=stats.norm.pdf(np.linspace(\n",
    "                     mu - 4*std_error, point_estimator, 100), mu, std_error),\n",
    "                 facecolor='red',\n",
    "                 alpha=0.35,\n",
    "                 label='red area %.3f' % (stats.norm.cdf(point_estimator, mu, std_error)))\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
